{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author: Viet Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purpose: the main purpose is to cluster venues (restaurants) in Melbourne's inner suburbs to see the similarity between areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# convert an address into latitude and longitude values\n",
    "!pip install geopy\n",
    "from geopy.geocoders import Nominatim \n",
    "\n",
    "# map rendering library\n",
    "!pip install folium\n",
    "import folium\n",
    "\n",
    "# library to handle requests\n",
    "import requests\n",
    "\n",
    "# to generate random colors\n",
    "import random\n",
    "\n",
    "# to handle processing strings\n",
    "import re\n",
    "\n",
    "#K-Means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Turn off the warnings\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define lists of Melbourne suburbs to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_suburbs = []\n",
    "\n",
    "city_suburbs = ['South Melbourne', 'Southbank', 'Fitzroy', 'Fitzroy North', 'Carlton', 'Collingwood', 'Melbourne'] #0.7 (chance) | #1 (comp)\n",
    "city_suburbs = np.array(city_suburbs)\n",
    "southyarra_suburbs = ['Prahran', 'Windsor', 'Cremorne', 'South Yarra', 'East Melbourne'] #0.75 (chance)  | #0.9 (comp)\n",
    "southyarra_suburbs = np.array(southyarra_suburbs)\n",
    "\n",
    "stkilda_suburbs = ['St Kilda', 'Balaclava', 'St Kilda East', 'St Kilda West'] #0.7 (chance) | #0.8 (comp)\n",
    "stkilda_suburbs = np.array(stkilda_suburbs)\n",
    "richmond_suburbs = ['Abbotsford', 'Richmond', 'Fairfield', 'Burnley', 'Clifton Hill'] #0.7 (chance) | #0.7 (comp)\n",
    "richmond_suburbs = np.array(richmond_suburbs)\n",
    "\n",
    "hawthorn_suburbs = ['Hawthorn', 'Hawthorn East', 'Camberwell', 'Kew', 'Box Hill'] #0.7 (chance) | #0.6 (comp)\n",
    "hawthorn_suburbs = np.array(hawthorn_suburbs)\n",
    "\n",
    "brighton_suburbs = ['Ripponlea', 'Elsternwick', 'Elwood', 'Brighton', 'Gardenvale', 'Ashwood'] #0.65 (chance) | #0.5 (comp)\n",
    "brighton_suburbs = np.array(brighton_suburbs)\n",
    "\n",
    "malvern_suburbs = ['Malvern', 'Malvern East', 'Ashburton', 'Glen Iris', 'Kooyong', 'Toorak', 'Armadale', 'Caulfield North', 'Caulfield'] #0.6 (chance) | #0.4 (comp)\n",
    "malvern_suburbs = np.array(malvern_suburbs)\n",
    "balwyn_suburbs = ['Balwyn', 'Balwyn North', 'Deepdene', 'Canterbury', 'Surrey Hills', 'Kew East'] #0.55 (chance) | #0.3 (comp)\n",
    "balwyn_suburbs = np.array(balwyn_suburbs)\n",
    "\n",
    "inner_suburbs = np.concatenate([city_suburbs, southyarra_suburbs, stkilda_suburbs, richmond_suburbs, \n",
    "                                hawthorn_suburbs, brighton_suburbs, malvern_suburbs, balwyn_suburbs])\n",
    "\n",
    "inner_suburbs = np.unique(inner_suburbs)\n",
    "\n",
    "print(\"Completed\", ' - Size', len(inner_suburbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define necessary variables to be used by Foursquare API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Foursquare Credentials and Version\n",
    "CLIENT_ID = 'QEC0BVYHEJCHQD5ZR4DJA1GCHNRQ5EIH3XOKPGG3Y3FLTV34' # your Foursquare ID\n",
    "CLIENT_SECRET = 'KWKBGZQ2GO14GX21K2IVEJEVIXHDA323JQEE1PEKXICD42BC' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "radius = 200\n",
    "LIMIT = 10\n",
    "state = \"VIC\"\n",
    "country = \"Australia\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to format collected address information into a standard form\n",
    "\n",
    "There are too many different formats of collected addresses from Foursquare API.\n",
    "It is important to make them having a standard format for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_types = [' road', ' street', ' rd', ' st', ' avenue', ' ave', ' parade', ' pde', ' lane', ' ln']\n",
    "delimiters = ['/', ',']\n",
    "\n",
    "def address_extract(raw_address, road_types):\n",
    "    \n",
    "    raw_address = raw_address.lower()\n",
    "\n",
    "    for i, value in enumerate(delimiters):\n",
    "        pos = raw_address.find(value)\n",
    "        if (pos != -1):\n",
    "            raw_address = raw_address[pos:]\n",
    "\n",
    "    for i, value in enumerate(raw_address):\n",
    "        if not (re.match('^[a-zA-Z ]*$', value)):\n",
    "            raw_address = raw_address.replace(value, '')\n",
    "\n",
    "    for i, value in enumerate(road_types):\n",
    "        if value in raw_address:\n",
    "            \n",
    "            if (value == road_types[0]):\n",
    "                raw_address = raw_address.replace(value, '_road')\n",
    "            \n",
    "            if (value == road_types[1]):\n",
    "                raw_address = raw_address.replace(value, '_street')\n",
    "                \n",
    "            if (value == road_types[2]):\n",
    "                raw_address = raw_address.replace(value, '_road')\n",
    "                \n",
    "            if (value == road_types[3]):\n",
    "                raw_address = raw_address.replace(value, '_street')\n",
    "                \n",
    "            if (value == road_types[4]):\n",
    "                raw_address = raw_address.replace(value, '_avenue')\n",
    "                \n",
    "            if (value == road_types[5]):\n",
    "                raw_address = raw_address.replace(value, '_avenue')\n",
    "                \n",
    "            if (value == road_types[6]):\n",
    "                raw_address = raw_address.replace(value, '_parade')\n",
    "                \n",
    "            if (value == road_types[7]):\n",
    "                raw_address = raw_address.replace(value, '_parade')\n",
    "                \n",
    "            if (value == road_types[8]):\n",
    "                raw_address = raw_address.replace(value, '_lane')\n",
    "                \n",
    "            if (value == road_types[9]):\n",
    "                raw_address = raw_address.replace(value, '_lane')\n",
    "            \n",
    "            break\n",
    "        \n",
    "    raw_address = raw_address.replace(' ', '')\n",
    "    raw_address = raw_address.replace('_', ' ')\n",
    "    raw_address = raw_address.title()\n",
    "    \n",
    "    if raw_address == ' Streetation Street':\n",
    "        return 'Flinders Street'\n",
    "    \n",
    "    return raw_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for suburb's postcode and geographical coordinate data (with high accuracy) with Foursquare API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists that hold suburb's geograpical coordinate\n",
    "postcodes = []\n",
    "suburbs = []\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "for i, suburb in enumerate(inner_suburbs):\n",
    "    url = 'https://api.foursquare.com/v2/venues/search?client_id={0}&client_secret={1}&near={2},{3},{4}&v={5}&radius={6}&limit={7}'.format(CLIENT_ID, CLIENT_SECRET, suburb, state, country, VERSION, radius, LIMIT)\n",
    "    \n",
    "    results = requests.get(url).json()\n",
    "    venues = results['response']['venues']\n",
    "        \n",
    "    postcode = lat = long = 0\n",
    "    for x in range(0, len(venues)):\n",
    "        if 'postalCode' not in venues[x]['location']:\n",
    "            continue\n",
    "        else:\n",
    "            postcode = venues[x]['location']['postalCode']\n",
    "            lat = venues[x]['location']['lat']\n",
    "            long = venues[x]['location']['lng']\n",
    "            break\n",
    "            \n",
    "            \n",
    "    # Filling data to defined lists\n",
    "    postcodes.append(postcode)\n",
    "    suburbs.append(suburb)\n",
    "    latitudes.append(lat)\n",
    "    longitudes.append(long)\n",
    "\n",
    "# Make the Python lists become Numpy array \n",
    "postcodes = np.array(postcodes)\n",
    "suburbs = np.array(suburbs)\n",
    "latitudes = np.array(latitudes)\n",
    "longitudes = np.array(longitudes)\n",
    "\n",
    "print(\"Lists initialisation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate suburbs_geo dataframe with suburb's data lists defined and initialised from the above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Dataframe with Melbourne's suburbs geographical coordinate data\n",
    "columns = ['Postcode', 'Suburb', 'Latitude', 'Longitude']\n",
    "data = np.array([postcodes, suburbs, latitudes, longitudes])\n",
    "suburbs_geo = pd.DataFrame(data.T, columns = columns)\n",
    "suburbs_geo.sort_values(by = 'Postcode', inplace = True)\n",
    "# Reset index\n",
    "suburbs_geo.reset_index(drop = True, inplace = True)\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the suburbs_geo dataframe to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburbs_geo.to_csv(\"suburb_geo.csv\", encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to format collected venue's city into a standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_name_extract(city):\n",
    "    \n",
    "    city = city.lower()\n",
    "    city = city.replace(' ', '')\n",
    "    \n",
    "    if city == 'southmelbourne':\n",
    "        return 'South Melbourne'\n",
    "    \n",
    "    if city == 'eastmelbourne':\n",
    "        return 'East Melbourne'\n",
    "    \n",
    "    if city == 'southyarra':\n",
    "        return 'South Yarra'\n",
    "    \n",
    "    if city == 'northcote':\n",
    "        return 'Northcote'\n",
    "    \n",
    "    if city == 'northrichmond':\n",
    "        return 'Richmond'\n",
    "    \n",
    "    if city == 'southbank':\n",
    "        return 'Southbank'\n",
    "    \n",
    "    if city == 'saintkilda':\n",
    "        return 'St Kilda'\n",
    "    \n",
    "    if city == 'elsternwick':\n",
    "        return 'Elsternwick'\n",
    "\n",
    "    if ',' in city:\n",
    "        pos = city.find(',')\n",
    "        city = city[0:pos]\n",
    "        \n",
    "    if '.' in city:\n",
    "        city = city.replace('.', '')\n",
    "        \n",
    "    if 'st' in city:\n",
    "        city = city.replace('st', 'st ')\n",
    "\n",
    "    words = ['east', 'west', 'south', 'north', 'hill', 'hills', 'iris']\n",
    "\n",
    "    for i, value in enumerate(words):\n",
    "        if value in city:\n",
    "            city = city.replace(value, ' ' + value)\n",
    "            break\n",
    "            \n",
    "    city = city.title()\n",
    "    \n",
    "    return city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to explore venues in a suburb and put them all into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploreVenues(data, query, radius, limit):\n",
    "    \n",
    "    df_columns = ['Suburb', 'Postcode', 'Suburb_Latitude', \n",
    "              'Suburb_Longitude', 'Venue', 'Category', \n",
    "              'Address', 'Venue_Latitude', 'Venue_Longitude', 'Label', 'Chance', 'Comp']\n",
    "        \n",
    "    venues_list=[]\n",
    "    \n",
    "    for postcode, lat, lng in zip(data['Postcode'], data['Latitude'], data['Longitude']):\n",
    "          \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?client_id={0}&client_secret={1}&ll={2},{3}&v={4}&query={5}&radius={6}&limit={7}'.format(CLIENT_ID, CLIENT_SECRET, lat, lng, VERSION, query, radius, limit)\n",
    "        \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        for x in range(0, len(results)):\n",
    "            venue_details = []\n",
    "            if 'address' not in results[x]['venue']['location']:\n",
    "                continue\n",
    "            elif 'city' not in results[x]['venue']['location']:\n",
    "                continue\n",
    "            else:\n",
    "                address = results[x]['venue']['location']['address']      \n",
    "                if (re.match('^[0-9]*$', address)):\n",
    "                    continue\n",
    "                else:\n",
    "                    # format suburb's name\n",
    "                    suburb = city_name_extract(results[x]['venue']['location']['city'])\n",
    "                    # format address information\n",
    "                    address = address_extract(address, road_types)\n",
    "                    \n",
    "                    # default values\n",
    "                    label = 0\n",
    "                    chance = 0.6\n",
    "                    comp = 0.75\n",
    "                    \n",
    "                    #1\n",
    "                    for i, value in enumerate(city_suburbs):\n",
    "                        if suburb == value:\n",
    "                            chance = 0.7\n",
    "                            comp = 0.9\n",
    "                            break\n",
    "                    #2      \n",
    "                    for i, value in enumerate(southyarra_suburbs):\n",
    "                        if suburb == value:\n",
    "                            chance = 0.75\n",
    "                            comp = 0.85\n",
    "                            break\n",
    "                    #3\n",
    "                    for i, value in enumerate(stkilda_suburbs):\n",
    "                        if suburb == value:\n",
    "                            chance = 0.7\n",
    "                            comp = 0.8\n",
    "                            break\n",
    "                    #4     \n",
    "                    for i, value in enumerate(richmond_suburbs):\n",
    "                        if suburb == value:\n",
    "                            chance = 0.7\n",
    "                            comp = 0.75\n",
    "                            break\n",
    "                    #5\n",
    "                    for i, value in enumerate(hawthorn_suburbs):\n",
    "                        if suburb == value:\n",
    "                            chance = 0.7\n",
    "                            comp = 0.7\n",
    "                            break \n",
    "                    #6       \n",
    "                    for i, value in enumerate(brighton_suburbs):\n",
    "                        if suburb == value:\n",
    "                            chance = 0.6\n",
    "                            comp = 0.6\n",
    "                            break \n",
    "                    #7\n",
    "                    for i, value in enumerate(malvern_suburbs):\n",
    "                        if suburb == value:\n",
    "                            chance = 0.6\n",
    "                            comp = 0.55\n",
    "                            break\n",
    "                    #8\n",
    "                    for i, value in enumerate(balwyn_suburbs):\n",
    "                        if suburb == value:\n",
    "                            chance = 0.5\n",
    "                            comp = 0.5\n",
    "                            break\n",
    "                    \n",
    "                    venue_details.append([suburb, postcode, lat, lng, results[x]['venue']['name'],\n",
    "                                          results[x]['venue']['categories'][0]['name'], address,\n",
    "                                          results[x]['venue']['location']['lat'], \n",
    "                                          results[x]['venue']['location']['lng'], label, chance, comp])\n",
    "                \n",
    "            venues_list.append(venue_details)\n",
    "\n",
    "    results_df = pd.DataFrame(columns = df_columns)\n",
    "    \n",
    "    for i, venue in enumerate(venues_list):\n",
    "        venue_df = pd.DataFrame(data = venue, columns = df_columns)\n",
    "        results_df = results_df.append(venue_df)\n",
    "    \n",
    "    results_df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to explore venues in all suburbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_venues(keyword, radius = 1300, limit = 100):\n",
    "\n",
    "    allvenues_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(0, suburbs_geo['Postcode'].count()):\n",
    "        sub_geo = suburbs_geo.iloc[[i]]\n",
    "        suburbvenues_df = exploreVenues(data=sub_geo, query=keyword, radius = radius, limit = limit)\n",
    "        allvenues_df = allvenues_df.append(suburbvenues_df)\n",
    "\n",
    "    allvenues_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    return allvenues_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate a clustered venues map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_map_cluster(venues_data, suburbs_geo, query):\n",
    "    \n",
    "    number_of_clusters = venues_data['Label'].max() + 1\n",
    "    \n",
    "    distinguishable_colors = ['red', 'blue', 'black', 'orange', 'green', 'cyan', 'purple', 'yellow', 'lime', 'fuchsia', 'indigo', 'brown']\n",
    "    colors = []\n",
    "    for i, value in enumerate(random.sample(range(0, len(distinguishable_colors)), number_of_clusters)):\n",
    "        colors.append(distinguishable_colors[value])\n",
    "        \n",
    "              \n",
    "    start_data = suburbs_geo[suburbs_geo['Suburb'] == query]\n",
    "    start_lat = float(start_data['Latitude'])\n",
    "    start_lng = float(start_data['Longitude'])\n",
    "    \n",
    "    # create map of the suburbs using latitude and longitude values\n",
    "    result_map = folium.Map(location=[start_lat, start_lng], zoom_start=13, width = '80%', height = '80%')\n",
    "    \n",
    "    # add markers (venues) to map\n",
    "    for lat, lng, label in zip(venues_data['Venue_Latitude'], venues_data['Venue_Longitude'], venues_data['Label']):\n",
    "        \n",
    "        if (number_of_clusters > 1):\n",
    "            color = colors[label]\n",
    "        else:\n",
    "            color = 'blue'\n",
    "        \n",
    "        #venue_label = folium.Popup(label, parse_html=True)\n",
    "        folium.CircleMarker([float(lat), float(lng)], radius=3, color=color, fill=True, fill_color=color, fill_opacity=1).add_to(result_map)\n",
    "    \n",
    "    if (number_of_clusters > 1):\n",
    "        \n",
    "        stats_df = venues_data\n",
    "        stats_df = stats_df.drop(labels = {'Suburb', 'Postcode', 'Suburb_Latitude', 'Suburb_Longitude', 'Venue_Latitude', 'Venue', 'Category', \n",
    "                               'Address', 'Venue_Longitude'}, axis = 1)\n",
    "        stats_df[['Chance', 'Comp']] = stats_df[['Chance', 'Comp']].astype('float')\n",
    "        stats_df = stats_df.groupby('Label').mean().reset_index()\n",
    "        \n",
    "        for i in range(0, number_of_clusters):\n",
    "        \n",
    "            chance = stats_df[stats_df['Label'] == i]['Chance'].values[0]\n",
    "            comp = stats_df[stats_df['Label'] == i]['Comp'].values[0]\n",
    "\n",
    "            print('Cluster', i, ' color', ': ', colors[i], '\\t', ' | ',\n",
    "                  'Chance getting customers rate: ', chance * 100, '%', ' | ',\n",
    "                  'Competition rate: ', comp * 100, '%')\n",
    "\n",
    "    return result_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to process generated dataframe from the previous steps with specific conditions and standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_venues_dataframe(data):\n",
    "    \n",
    "    venues_list = data\n",
    "    venues_list = venues_list.drop_duplicates(subset = ['Venue'], keep = 'first').reset_index(drop = True)\n",
    "    venues_list = venues_list.drop(labels = 'Postcode', axis = 1)\n",
    "\n",
    "    # generate a dataframe of venues with incorrect suburb\n",
    "    incorrect_suburb_venues = venues_list[venues_list['Suburb'] == 'Melbourne']\n",
    "    # also drop the suburb column which contains incorrect information\n",
    "    incorrect_suburb_venues = incorrect_suburb_venues.drop(labels = {'Suburb'}, axis = 1)\n",
    "    \n",
    "    # drop those incorrect venues from the venues_list dataframe\n",
    "    venues_list = venues_list.drop(venues_list[venues_list['Suburb'] == 'Melbourne'].index)\n",
    "    \n",
    "    # using suburbs_geo dataframe to merge with the incorrect_suburb_venues dataframe to find the correct suburbs\n",
    "    fixed_suburb_venues = incorrect_suburb_venues.merge(suburbs_geo, how = 'left', left_on=['Suburb_Latitude', 'Suburb_Longitude'], right_on = ['Latitude', 'Longitude']).reset_index(drop = True)\n",
    "    \n",
    "    # drop unnecessary columns after merging\n",
    "    fixed_suburb_venues = fixed_suburb_venues.drop(labels = {'Postcode', 'Suburb_Latitude', 'Suburb_Longitude', 'Latitude', 'Longitude'}, axis = 1)\n",
    "    \n",
    "    # and reorder the columns for merger dataframe\n",
    "    fixed_suburb_venues = fixed_suburb_venues[['Suburb', 'Venue', 'Category', 'Address', 'Venue_Latitude', 'Venue_Longitude', 'Label', 'Chance', 'Comp']]\n",
    "    \n",
    "    # update venues_list dataframe with fixed_suburb_venues dataframe by appending\n",
    "    venues_list = venues_list.drop(labels = {'Suburb_Latitude', 'Suburb_Longitude'}, axis = 1)\n",
    "    venues_list = venues_list.append(fixed_suburb_venues).reset_index(drop = True)\n",
    "    \n",
    "    # generate dataframe count the frequency of each suburb in venues_list dataframe \n",
    "    suburb_count_df = venues_list.groupby(['Suburb']).count().reset_index()\n",
    "    # we only need to take suburbs that appear a least 4 times\n",
    "    suburb_count_df = suburb_count_df.drop(suburb_count_df[suburb_count_df['Address'] < 4].index)\n",
    "    # we only need to know the name of those suburbs that we want to keep\n",
    "    satisfied_suburbs_df = suburb_count_df[['Suburb']]\n",
    "    # now we will fill up information for list of suburbs we kept in previous step\n",
    "    satisfied_suburbs_df = satisfied_suburbs_df.merge(venues_list, how = 'left', left_on = ['Suburb'], right_on = ['Suburb'])\n",
    "    \n",
    "    # now update the venues_list dataframe\n",
    "    venues_list = satisfied_suburbs_df\n",
    "    # we again generate a new dataframe but this one displays the frequency of the addresses instead \n",
    "    address_count_df = satisfied_suburbs_df.groupby('Address').count().reset_index()\n",
    "    # we won't keep addresses that appear less than 2 times\n",
    "    address_count_df = address_count_df.drop(address_count_df[address_count_df['Suburb'] < 2].index)\n",
    "    # now we have list of addresses we want\n",
    "    satisfied_addresses_df = address_count_df[['Address']]\n",
    "    # fill up information for those address\n",
    "    satisfied_addresses_df = satisfied_addresses_df.merge(venues_list, how = 'left', right_on = ['Address'], left_on = ['Address'])\n",
    "\n",
    "    # and update venues_list dataframe\n",
    "    venues_list = satisfied_addresses_df\n",
    "    \n",
    "    return venues_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to process clustering with K-means algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_algorithm(venues_data, n_clusters):\n",
    "    \n",
    "    kmeans_df = data[['Suburb', 'Address', 'Chance', 'Comp']]\n",
    "\n",
    "    train_df = kmeans_df[['Chance', 'Comp']]\n",
    "    train_df = pd.concat([train_df, pd.get_dummies(kmeans_df['Suburb'])], axis = 1)\n",
    "    train_df = pd.concat([train_df, pd.get_dummies(kmeans_df['Address'])], axis = 1)\n",
    "    train_df = train_df.astype('float')\n",
    "\n",
    "    X = train_df.values[:, 1:]\n",
    "    X = np.nan_to_num(X)\n",
    "\n",
    "    k_means = KMeans(init = \"k-means++\", n_clusters = n_clusters, n_init = 12)\n",
    "    k_means.fit(X)\n",
    "    labels = k_means.labels_\n",
    "    kmeans_df['Label'] = labels\n",
    "    \n",
    "    kmeans_df = kmeans_df[['Address', 'Suburb', 'Chance', 'Comp', 'Label']]\n",
    "    \n",
    "    result_df = data.drop(labels = 'Label', axis = 1)\n",
    "    result_df['Label'] = kmeans_df['Label']\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After defined all necessary elements, it's time to run the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = search_venues(keyword = 'Restaurant')\n",
    "# save search results\n",
    "data.to_csv('search_results.csv', encoding='utf-8', index = False)\n",
    "# generate dataframe holds found venues information\n",
    "venues_list = generate_venues_dataframe(data)\n",
    "print(\"Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before clustering\n",
    "generate_map_cluster(venues_list, suburbs_geo, 'Hawthorn') #hawthorn is the centre of the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "fit_venues_list = kmeans_algorithm(venues_list, n_clusters = 5)\n",
    "print('Completed!') # 5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after clustering visualise clusters on map\n",
    "generate_map_cluster(fit_venues_list, suburbs_geo, 'Hawthorn') #Hawthorn is the centre of the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
